#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Twisted hosts our website and helps with async tasks.
# The application threads are structured in the following way:
#
# reactor
#   -- workers: x threads
#   -- website: y threads
#
# Command line arguments follow GNU conventions
import os
from getopt import gnu_getopt
from sys import argv, stderr
from twisted.internet import reactor    # Import twisted modules
from twisted.web.wsgi import WSGIResource
from twisted.web.server import Site
from twisted.python.threadpool import ThreadPool
from twisted.python import log

# Configuration is stored in a simple ini file
from configparser import ConfigParser, ExtendedInterpolation
# import database classes
from balikator.db import reflect
from balikator.db_int import reflect_internal
from balikator.db_dspace import reflect_dspace
# import manager
from balikator.manager import Manager
# import top-level workflows
from balikator.workflows.workflow_theses import workflow_theses
# Data are accessed through  SQLSoup, using SQLAlchemy
from sqlalchemy.orm import scoped_session, sessionmaker
from sqlalchemy import create_engine
from sqlsoup import SQLSoup

def thread_died(err):
    if hasattr(err, 'printTraceback'):
        err.printTraceback()
    reactor.stop()

if __name__ == '__main__':
    def do_start(config):
        # Start twisted logging to console
        log.startLogging(stderr)

        # prepare database connections

        # get database connection string
        sis_url = config.get('database', 'sis_url')
        db_url_internal = config.get('database', 'internal_url')
        dspace_url = config.get('database', 'dspace_url')

        # default to much saner database query defaults and always
        # commit and/or flush statements explicitly
        factory = sessionmaker(autocommit=False, autoflush=False)

        # INTERNAL database
        
        engine_internal = create_engine(db_url_internal, encoding='utf-8', client_encoding='utf8')
        session_internal = scoped_session(factory)
        db_int_meta = reflect_internal(engine_internal)
        db_internal = SQLSoup(db_int_meta, session=session_internal)

        # SIS database
        # FIXME
        engine_sis = create_engine(sis_url, encoding='utf-8')
        session_sis = scoped_session(factory)
        db_sis = SQLSoup(reflect(engine_sis), session=session_sis)

        # DSPACE database
        engine_dspace = create_engine(dspace_url, encoding='utf-8', client_encoding='utf8')
        session_dspace = scoped_session(factory)
        db_dspace = SQLSoup(reflect_dspace(engine_dspace), session=session_dspace)

        # initialize all workflows in internal database if there are some missing
        insert_workflows(db_internal)

        #FIXME: This needs to be run only when restart method is called. Currently, there is no restart method.
        # restart_workflows(db=db_internal)

        # instantiate doc workflow
        wf_theses = workflow_theses(db_int=db_internal, db_sis=db_sis, db_dspace=db_dspace, config=config)

        # instantiate manager
        manager = Manager(db_int=db_internal, db_sis=db_sis, config=config,
                          workflow_theses=wf_theses, workflow_obd=None)

        # schedule call to the manager right after we finish here
        reactor.callLater(0, manager.start_theses)

        # run the twisted reactor until the user terminates us
        reactor.run()

    def insert_workflows(db):
        for option, workflow_conf in config.items('workflows'):
            workflow_id = None
            workflow_name = None

            workflow_list = list()

            workflow_id, workflow_name = str(workflow_conf).split(',')
            log.msg("INSERT WORKFLOWS workflow_id:", workflow_id)
            log.msg("INSERT WORKFLOWS workflow_name:", workflow_name )
            if db.workflow.filter_by(id=workflow_id).first() is None:
                db.workflow.insert(id=workflow_id, name=workflow_name)

            else:
                log.msg("INSERT WORKFLOWS: Workflow with this ID is already in the database.")
        db.commit()

    def restart_workflows(db):
        workflows = db.workflow.all()
        for workflow in workflows:
            log.msg("Restarting workflow", workflow.id, workflow.name)
            db.workflow.filter_by(id=workflow.id).update({'state': 'stopped'})
            db.commit()
            log.msg("Workflow state set to", db.workflow.filter_by(id=workflow.id).first().state)

    def do_help(*args, **kwargs):
        return None

    def do_version(*args, **kwargs):
        return None

    # Parse command line arguments
    opts, args = gnu_getopt(argv, 'hVcwr:', ['help', 'version', 'config=', 'workflows', 'restart'])

    action = do_start
    config_path = './config/balikator.ini'

    # set environmental variable for ORACLE SORTING
    # Oracle is sending data back in UTF-16 by default and uses a NLS sorting not compatible with Czech by default.
    # Setting corrent NLS_LANG environment variable deals with this issue.
    os.environ["NLS_LANG"] = ".UTF8"

    for k, v in opts:
        if k in ('--help', '-h'):
            action = do_help
        elif k in ('--version', '-V'):
            action = do_version
        elif k in ('--config', '-c'):
            config_path = v
        elif k in ('--workflows', '-w'):
            wf_init = True
        elif k in ('--restart', '-r'):
            wf_restart = True

    # Load the configuration from file.
    config = ConfigParser(interpolation=ExtendedInterpolation())
    config.read(config_path)

    # Perform selected action.
    action(config=config)
